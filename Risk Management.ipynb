{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40572196-dee9-468b-b7d1-ca36478f3d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "import scipy.optimize as sco\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1350136-8bbb-4649-9562-1cbd06fdc7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_close(tickers,\n",
    "              start=datetime.date(datetime.date.today().year - 1, \n",
    "                datetime.date.today().month, \n",
    "                datetime.date.today().day)\n",
    "                ,end=datetime.date.today()):\n",
    "    \n",
    "    data=pd.DataFrame()\n",
    "    for ticker in tickers:\n",
    "\n",
    "        try:\n",
    "\n",
    "            yahoo_data=yf.Ticker(ticker)\n",
    "            stock_price=yahoo_data.history(start=start,end=end,interval='1d').reset_index()\n",
    "            stock_price['Date']=stock_price['Date'].dt.tz_localize(None)\n",
    "            stock_price=stock_price.set_index('Date')\n",
    "            stock_price[ticker]=stock_price['Close']+stock_price['Dividends'].shift(periods=-1)\n",
    "            data=pd.concat([data,stock_price[ticker]],axis=1)\n",
    "\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "078644e5-bc77-4e47-873a-42a056a83df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks=pd.read_html('https://en.wikipedia.org/wiki/EURO_STOXX_50')[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68eb0acf-e0d2-4cb6-a684-491ef5d63189",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers=stocks['Ticker'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66df28bf-ffc6-4dfe-84e6-d9eec29f6e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=get_close(tickers,\"2023-01-01\")\n",
    "data=data.dropna()\n",
    "n=len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5136057-2b87-4f55-b8df-1d13a80c956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns=np.log(1+data.pct_change())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991c3be5-6004-4771-a632-a1724782bccf",
   "metadata": {},
   "source": [
    "# Portfolio Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "adfdfce4-1927-4494-91a6-7c16d3d1fcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def halton_sequences(number,base=2):\n",
    "    \n",
    "    inv_base=1/base\n",
    "    \n",
    "    i=number\n",
    "    halton=0\n",
    "    \n",
    "    while i>0:\n",
    "        \n",
    "        digit = i%base\n",
    "        halton=halton + digit*inv_base\n",
    "        i=(i-digit)/base\n",
    "        inv_base=inv_base/base\n",
    "        \n",
    "    return halton\n",
    "\n",
    "def generate_halton(iterations,dimensions=1,base=2):\n",
    "    \n",
    "    rng = np.random.default_rng()\n",
    "    matrix=[]\n",
    "    haltons=[]\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        halton=halton_sequences(i,base=base)\n",
    "        haltons.append(halton)\n",
    "    \n",
    "    for dim in range(dimensions):\n",
    "        \n",
    "        matrix.append(haltons)\n",
    "    \n",
    "    matrix = rng.permuted(matrix, axis=1)\n",
    "    return matrix\n",
    "\n",
    "def near_psd(x, epsilon=0):\n",
    "\n",
    "    if min(np.linalg.eigvals(x)) > epsilon:\n",
    "        return x\n",
    "\n",
    "    n = x.shape[0]\n",
    "    var_list = np.array(np.sqrt(np.diag(x)))\n",
    "    y = np.array([[x[i, j]/(var_list[i]*var_list[j]) for i in xrange(n)] for j in xrange(n)])\n",
    "\n",
    "    eigval, eigvec = np.linalg.eig(y)\n",
    "    val = np.matrix(np.maximum(eigval, epsilon))\n",
    "    vec = np.matrix(eigvec)\n",
    "    T = 1/(np.multiply(vec, vec) * val.T)\n",
    "    T = np.matrix(np.sqrt(np.diag(np.array(T).reshape((n)) )))\n",
    "    B = T * vec * np.diag(np.array(np.sqrt(val)).reshape((n)))\n",
    "    near_corr = B*B.T    \n",
    "\n",
    "    near_cov = np.array([[near_corr[i, j]*(var_list[i]*var_list[j]) for i in xrange(n)] for j in xrange(n)])\n",
    "    return near_cov\n",
    "\n",
    "def performance(perf,weights):\n",
    "    \n",
    "    return np.dot(perf,weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7b46eddd-c46d-48d0-9fcf-abf758debb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Portfolio:\n",
    "    \n",
    "    def __init__(self,data):\n",
    "        \n",
    "        self.data=data\n",
    "\n",
    "    def portfolio(self,weights):\n",
    "            \n",
    "        portfolio=pd.DataFrame()\n",
    "        portfolio['Portfolio']=np.sum(weights*returns,axis=1)\n",
    "        \n",
    "        return portfolio\n",
    "    \n",
    "    def performance(self,weights):\n",
    "        performance=np.sum(self.data*weights).mean()*252\n",
    "        return performance\n",
    "    \n",
    "    def variance(self,weights):\n",
    "        variance=np.sqrt(np.dot(weights.T,np.dot(self.data.cov(),weights)))*np.sqrt(252)\n",
    "        return variance\n",
    "    \n",
    "    def sharpe_ratio(weights):\n",
    "            return self.performance(weights)/self.variance(weights)\n",
    "\n",
    "    def optimize(self,objective='minimum_variance',constraints=False):\n",
    "        \n",
    "            \n",
    "        def sum_equal_one(weight):\n",
    "            return np.sum(weight) - 1   \n",
    "        \n",
    "        def sharpe_ratio(weights):\n",
    "            return - self.performance(weights)/self.variance(weights)\n",
    "        \n",
    "        def variance(weights):\n",
    "            variance=np.sqrt(np.dot(weights.T,np.dot(self.data.cov(),weights)))*np.sqrt(252)\n",
    "            return variance\n",
    "        \n",
    "        n_assets = len(self.data.columns)\n",
    "        weight = np.array([1 / n_assets] * n_assets)\n",
    "        bounds = tuple((0, 1) for _ in range(n_assets))\n",
    "        \n",
    "        if not constraints:\n",
    "            \n",
    "            constraints = [{'type': 'eq', 'fun': sum_equal_one}]\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            constraints=[{'type': 'eq', 'fun': sum_equal_one}]+constraints\n",
    "        \n",
    "        if objective=='minimum_variance':\n",
    "\n",
    "            optimum_weights = sco.minimize(variance, weight, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "        \n",
    "        elif objective=='sharpe_ratio':\n",
    "            \n",
    "            optimum_weights = sco.minimize(sharpe_ratio, weight, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            print(\"Objective function undefined\")\n",
    "            \n",
    "            \n",
    "        return optimum_weights.x\n",
    "    \n",
    "    def black_Litterman(self,P,Q,weights,risk_aversion,tau=0.025):\n",
    "        \n",
    "        implied_returns=risk_aversion*self.data.cov().dot(weights).squeeze()\n",
    "        omega=np.diag(np.diag(P.dot(tau*self.data.cov()).dot(P.T)))\n",
    "        sigma_scaled=self.data.cov()*tau\n",
    "        BL_returns= implied_returns + sigma_scaled.dot(P.T).dot(np.linalg.inv(P.dot(sigma_scaled).dot(P.T))+omega).dot(Q-P.dot(implied_returns))\n",
    "        inv_cov=np.linalg.inv(self.data.cov())\n",
    "        BL_weights=inv_cov.dot(BL_returns)\n",
    "        BL_weights=BL_weights/BL_weights.sum()\n",
    "        \n",
    "        return BL_weights,BL_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34878d2-f683-4e41-8d4d-047bdf77a8fe",
   "metadata": {},
   "source": [
    "## Risk Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ca4389e7-5250-45e7-83b8-5dba2353231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiskAnalysis(Portfolio):\n",
    "    \n",
    "    def __init__(self,returns):\n",
    "        \n",
    "        self.returns=returns\n",
    "        super().__init__(data=returns)\n",
    "        \n",
    "\n",
    "    def historical_var(self,weights,last_days=False,Q=5):\n",
    "\n",
    "        performance=super().portfolio(weights)\n",
    "        \n",
    "        if last_days:\n",
    "            performance=performance[-last_days:]\n",
    "            \n",
    "        var=np.percentile(performance,Q)\n",
    "        cvar=performance[performance<var].mean().values[0]\n",
    "        \n",
    "        return var,cvar\n",
    "        \n",
    "    def parametric_var(self,weights,Q=0.95):\n",
    "        \n",
    "        intervals=np.arange(Q, 1, 0.0005, dtype=float)\n",
    "        \n",
    "        variance=super().variance(weights)\n",
    "        VaR=variance/np.sqrt(252)*norm(loc =0 , scale = 1).ppf(1-Q)\n",
    "        CVaR=variance/np.sqrt(252)*norm(loc =0 , scale = 1).ppf(1-intervals).mean()\n",
    "        \n",
    "        return VaR,CVaR\n",
    "        \n",
    "        \n",
    "    def multivariate_distribution(self,mean=returns.mean(),\n",
    "                    covariance=near_psd(returns.cov()),\n",
    "                    iterations=10000):\n",
    "        \n",
    "        multivariate=np.random.multivariate_normal(mean,covariance,iterations)\n",
    "        \n",
    "        \n",
    "        return multivariate\n",
    "    \n",
    "    def pca(self):\n",
    "        \n",
    "        pass\n",
    "                \n",
    "    \n",
    "    def monte_carlo(self,spot,horizon=20/250,iterations=100000,stress_factor=1.0):\n",
    "        \n",
    "        \n",
    "        \n",
    "        num_asset=len(self.returns.columns)\n",
    "        #haltons=generate_halton(iterations,num_asset,base=2)\n",
    "        randoms=np.random.normal(size=(10000,50)).T\n",
    "        \n",
    "        #cree une matrice de stress pour envoyer des shock sur les corrélations\n",
    "        if type(stress_factor)==float:\n",
    "            \n",
    "            stress_vec=np.linspace(stress_factor,stress_factor,num_asset)\n",
    "            \n",
    "        else: \n",
    "            \n",
    "            stress_vec=stress_factor\n",
    "        \n",
    "        # Multiplication des volatilités par un facteur de stress\n",
    "        \n",
    "        vol=self.returns.std()*np.sqrt(250)*stress_vec\n",
    "        \n",
    "        # Cree une matrice diagonale de facteurs de stress pour perturber la matrice de covariance\n",
    "        \n",
    "        stress_matrix=np.diag(stress_vec)\n",
    "        stress_matrix=pd.DataFrame(stress_matrix,columns=self.returns.columns,index=self.returns.columns)\n",
    "        \n",
    "        \n",
    "        # trouve la matrice de covariance semie definie positive \n",
    "        # la plus proche apres avoir appliquée les choque a la matrice de covariance\n",
    "        \n",
    "        stressed_cov=self.returns.cov().dot(stress_matrix)\n",
    "        stressed_std=np.sqrt(np.diag(stressed_cov))\n",
    "        corr_matrix=stressed_cov/np.outer(stressed_std,stressed_std)\n",
    "        sdp_corr_matrix=near_psd(corr_matrix)\n",
    "        \n",
    "        #calcule la decomposition de Cholesky \n",
    "        cholesky=np.linalg.cholesky(corr_matrix)\n",
    "            \n",
    "        drift=np.exp(-0.5*horizon*vol**2)\n",
    "        factors=spot*drift\n",
    "        factors_vec=factors.to_numpy().reshape(num_asset,-1)\n",
    "                \n",
    "        simulation=np.matmul(cholesky,randoms).T\n",
    "        simulation=pd.DataFrame(simulation)\n",
    "        simulation.columns=self.returns.columns\n",
    " \n",
    "        \n",
    "        monte_carlo=factors_vec.T*np.exp(simulation.dot(np.diag(vol))*np.sqrt(horizon))\n",
    "        monte_carlo=pd.DataFrame(monte_carlo)\n",
    "        monte_carlo.columns=self.returns.columns\n",
    "        perf_monte_carlo=np.log(monte_carlo/spot)\n",
    "        \n",
    "        return monte_carlo,perf_monte_carlo\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "033757c3-7862-4cd5-85fa-2ef36d17696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=RiskAnalysis(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "eff9b995-2d49-4abc-bde4-2319b05928ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=test.optimize(objective=\"sharpe_ratio\",constraints=[{'type': 'ineq', 'fun': lambda weights: 0.1 - weights}])\n",
    "weights=np.round(weights,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "64112844-08d0-48ae-98e6-cb185952fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=np.random.rand(50)\n",
    "weights=weights/weights.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "0bb480c7-5f67-47ff-9a7d-3fdb3190b10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.015124230293755791"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var,cvar=test.historical_var(weights)\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9f580858-1e07-4e3c-a84b-ad37ea881b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.015499485864528373, -0.01986605550782164)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var,cvar=test.parametric_var(weights)\n",
    "var,cvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2c788d10-aa11-42de-9a7b-0bd312c8c0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.015049721014351095, -0.018964424176377014)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf=performance(test.multivariate_distribution(),weights)\n",
    "var=np.percentile(perf,5)\n",
    "cvar=perf[perf<var].mean()\n",
    "\n",
    "var,cvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1884cce4-1b61-4dc8-b99b-533b50d2e789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.015667109856313092, -0.01977927346981786)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spot=data.iloc[-1]\n",
    "monte_carlo=test.monte_carlo(spot,horizon=1/250,stress_factor=1.0)\n",
    "perf=performance(monte_carlo[1],weights)\n",
    "var=np.percentile(perf,5)\n",
    "cvar=perf[perf<var].mean()\n",
    "\n",
    "var,cvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "71e00427-9ca3-4c12-bd14-87596aa37348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADS.DE      -0.025521\n",
       "ADYEN.AS    -0.251950\n",
       "AD.AS       -0.002698\n",
       "AI.PA       -0.012825\n",
       "AIR.PA      -0.031177\n",
       "ALV.DE      -0.062716\n",
       "ABI.BR      -0.007270\n",
       "ASML.AS     -0.204148\n",
       "CS.PA       -0.014034\n",
       "BAS.DE      -0.008907\n",
       "BAYN.DE     -0.005180\n",
       "BBVA.MC     -0.002271\n",
       "SAN.MC      -0.001410\n",
       "BMW.DE       0.011246\n",
       "BNP.PA      -0.015224\n",
       "BN.PA       -0.001383\n",
       "DB1.DE      -0.035903\n",
       "DHL.DE      -0.008848\n",
       "DTE.DE       0.000085\n",
       "ENEL.MI     -0.000614\n",
       "ENI.MI      -0.001552\n",
       "EL.PA       -0.013884\n",
       "RACE.MI     -0.052244\n",
       "FLTR.IR      0.005324\n",
       "RMS.PA       0.178910\n",
       "IBE.MC      -0.001205\n",
       "ITX.MC      -0.001420\n",
       "IFX.DE      -0.007833\n",
       "INGA.AS     -0.003058\n",
       "ISP.MI      -0.000373\n",
       "KER.PA      -0.024391\n",
       "OR.PA       -0.006122\n",
       "MC.PA       -0.103936\n",
       "MBG.DE      -0.000921\n",
       "MUV2.DE     -0.038359\n",
       "NOKIA.HE    -0.000588\n",
       "NDA-FI.HE   -0.003291\n",
       "RI.PA        0.005951\n",
       "PRX.AS      -0.001050\n",
       "SAF.PA      -0.005011\n",
       "SGO.PA      -0.013715\n",
       "SAN.PA      -0.015373\n",
       "SAP.DE      -0.033519\n",
       "SU.PA       -0.030908\n",
       "SIE.DE      -0.020599\n",
       "STLAM.MI    -0.000728\n",
       "TTE.PA      -0.005316\n",
       "DG.PA       -0.018534\n",
       "UCG.MI      -0.004305\n",
       "VOW.DE      -0.005859\n",
       "dtype: float64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monte_carlo[0].mean()-spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30628b9-ed3a-4bf3-be26-b1478d3e2c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517bd2db-cad7-4697-8baf-ec2a4fe823b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eabf71a-da4a-41fe-ae44-49be4f20ab20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
